{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "rc = Client()\n",
    "dv = rc[:]\n",
    "\n",
    "@dv.parallel(block = True)\n",
    "def extract_features(subjects):\n",
    "\n",
    "    from preprocess import preprocess_location, preprocess_reason\n",
    "    import csv\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from get_data_at_location import get_data_at_location\n",
    "    from calculate_confusion_matrix import calculate_confusion_matrix\n",
    "    import math\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from scipy import stats\n",
    "    from count_transitions import count_transitions\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    save_results = True\n",
    "    break_locations = False # generate separate locations for each of the meniotned locations\n",
    "    remove_vehicle = True\n",
    "\n",
    "    data_dir = 'data/'\n",
    "#     data_dir_orig = '/home/sohrob/Dropbox/Data/CS120/'\n",
    "\n",
    "    fsq_map = {'Nightlife Spot':'Nightlife Spot (Bar, Club)', 'Outdoors & Recreation':'Outdoors & Recreation',\\\n",
    "              'Arts & Entertainment':'Arts & Entertainment (Theater, Music Venue, Etc.)',\\\n",
    "              'Professional & Other Places':'Professional or Medical Office',\\\n",
    "              'Food':'Food (Restaurant, Cafe)', 'Residence':'Home', 'Shop & Service':'Shop or Store', \\\n",
    "              'Travel & Transport':'Travel or Transport (Airport, Bus Stop, Train Station, Etc.)'}\n",
    "\n",
    "    # building one hot encoder for foursquare locations (as extra features)\n",
    "    state7 = np.array(fsq_map.values()+['Unknown'])\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(state7)\n",
    "    state7_code = le.transform(state7)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(state7_code.reshape(-1, 1))\n",
    "\n",
    "    # subjects = os.listdir(data_dir)\n",
    "\n",
    "    for subj in subjects:\n",
    "\n",
    "        print subj\n",
    "\n",
    "        subject_dir = data_dir + subj + '/'\n",
    "        samples = os.listdir(subject_dir)\n",
    "\n",
    "        # checking in the original directory if the subject has app data\n",
    "#         sensors = os.listdir(data_dir_orig+subj)\n",
    "#         if 'app.csv' in sensors:\n",
    "#             has_app_data = True\n",
    "#         else:\n",
    "#             has_app_data = False\n",
    "\n",
    "        # initialization\n",
    "        feature = pd.DataFrame()\n",
    "        target = pd.DataFrame()\n",
    "\n",
    "        ind_last = 0\n",
    "\n",
    "        for (i,samp) in enumerate(samples):\n",
    "\n",
    "            sensor_dir = subject_dir + samp + '/'\n",
    "            sensors = os.listdir(sensor_dir)\n",
    "\n",
    "            # reading semantic location data and skipping if it does not exist\n",
    "            if 'eml.csv' in sensors:\n",
    "                filename = sensor_dir+'eml.csv'\n",
    "                data = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "                # removing Vehicle category\n",
    "                if remove_vehicle and data.loc[0,6]=='[\"Vehicle\"]':\n",
    "                    print 'vehicle category skipped'\n",
    "                    continue\n",
    "                if break_locations:\n",
    "                    target.loc[ind_last, 'location'] = data.loc[0,6]\n",
    "                else:\n",
    "                    target.loc[ind_last, 'location'] = preprocess_location(data.loc[0,6], parse=False)\n",
    "                target.loc[ind_last, 'reason'] = preprocess_reason(data.loc[0,7], parse=False)\n",
    "                target.loc[ind_last, 'accomplishment'] = data.loc[0,8]\n",
    "                target.loc[ind_last, 'pleasure'] = data.loc[0,9]\n",
    "            else:\n",
    "                print 'subject {} does not have location report data at i. skipping'.format(subject,samp)\n",
    "                continue\n",
    "\n",
    "            if 'fsq2.csv' in sensors:\n",
    "                data_fsq = pd.read_csv(sensor_dir+'fsq2.csv', delimiter='\\t', header=None)\n",
    "                loc_fsq = data_fsq.loc[10,1]\n",
    "                distance_fsq = float(data_fsq.loc[11,1])\n",
    "\n",
    "                # converting foursquare category name to standard name\n",
    "                if loc_fsq in fsq_map:\n",
    "                    loc_fsq = fsq_map[loc_fsq]\n",
    "                else:\n",
    "                    loc_fsq = 'Unknown'\n",
    "\n",
    "            else:\n",
    "                loc_fsq = 'Unknown'\n",
    "                distance_fsq = np.nan\n",
    "\n",
    "            target.loc[ind_last, 'fsq'] = loc_fsq\n",
    "\n",
    "            ## sensor features\n",
    "            # light\n",
    "            if 'lgt.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'lgt.csv', delimiter='\\t', header=None)\n",
    "                lgt = data[:][1]\n",
    "                feature.loc[ind_last, 'lgt mean'] = np.nanmean(lgt)\n",
    "                feature.loc[ind_last, 'lgt std'] = np.nanstd(lgt)\n",
    "                feature.loc[ind_last, 'lgt off'] = np.sum(lgt==0)/float(lgt.size)\n",
    "                feature.loc[ind_last, 'lgt zcrossing'] = np.sum(np.diff(np.sign(lgt-np.nanmean(lgt))))/float(lgt.size)\n",
    "                feature.loc[ind_last, 'lgt skew'] = stats.skew(lgt)\n",
    "                feature.loc[ind_last, 'lgt kurt'] = stats.kurtosis(lgt)\n",
    "            else:\n",
    "                feature.loc[ind_last, 'lgt mean'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt std'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt off'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt zcrossing'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt skew'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt kurt'] = np.nan\n",
    "\n",
    "            # audio\n",
    "            if 'aud.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'aud.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'aud mean'] = np.nanmean(data[:][1])\n",
    "                feature.loc[ind_last, 'aud std'] = np.nanstd(data[:][1])\n",
    "                feature.loc[ind_last, 'aud skew'] = stats.skew(data[:][1])\n",
    "                feature.loc[ind_last, 'aud kurt'] = stats.kurtosis(data[:][1])\n",
    "                feature.loc[ind_last, 'aud frq mean'] = np.nanmean(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq std'] = np.nanstd(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq skew'] = stats.skew(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq kurt'] = stats.kurtosis(data[:][2])\n",
    "            else:\n",
    "                feature.loc[ind_last, 'aud mean'] = np.nan\n",
    "                feature.loc[ind_last, 'aud std'] = np.nan\n",
    "                feature.loc[ind_last, 'aud skew'] = np.nan\n",
    "                feature.loc[ind_last, 'aud kurt'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq mean'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq std'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq skew'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq kurt'] = np.nan\n",
    "\n",
    "\n",
    "            # screen\n",
    "            if 'scr.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'scr.csv', delimiter='\\t', header=None)\n",
    "                if data[:][0].size>=2:\n",
    "                    deltat = data[0][data[0][:].size-1] - data[0][0]\n",
    "                    if deltat!=0:\n",
    "                        scr_dur = np.array([])\n",
    "                        scr_frq = 0\n",
    "                        for j in range(data[1][:].size-1):\n",
    "                            if data[1][j]=='True' and data[1][j+1]=='False':\n",
    "                                scr_dur = np.append(scr_dur, data[0][j+1]-data[0][j])\n",
    "                                scr_frq += 1\n",
    "                        feature.loc[ind_last, 'scr frq'] = scr_frq/float(deltat)\n",
    "                        feature.loc[ind_last, 'scr dur mean'] = np.mean(scr_dur)\n",
    "                        feature.loc[ind_last, 'scr dur std'] = np.std(scr_dur)\n",
    "                    else:\n",
    "                        feature.loc[ind_last, 'scr frq'] = np.nan\n",
    "                        feature.loc[ind_last, 'scr dur mean'] = np.nan\n",
    "                        feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "                else:\n",
    "                    feature.loc[ind_last, 'scr frq'] = 0\n",
    "                    feature.loc[ind_last, 'scr dur mean'] = 0\n",
    "                    feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "            else:\n",
    "                feature.loc[ind_last, 'scr frq'] = 0\n",
    "                feature.loc[ind_last, 'scr dur mean'] = 0\n",
    "                feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "\n",
    "            # activity\n",
    "            if 'act.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'act.csv', delimiter='\\t', header=None)\n",
    "                n = float(data[0][:].size)\n",
    "                feature.loc[ind_last, 'still'] = np.sum(data[1][:]=='STILL')/n\n",
    "                feature.loc[ind_last, 'tilting'] = np.sum(data[1][:]=='TILTING')/n\n",
    "                feature.loc[ind_last, 'walking'] = np.sum(data[1][:]=='ONFOOT')/n\n",
    "                feature.loc[ind_last, 'unknown act'] = np.sum(data[1][:]=='UNKNOWN')/n\n",
    "                feature.loc[ind_last, 'still-walking'] = count_transitions(data[1][:],'STILL','ONFOOT')/n\n",
    "                feature.loc[ind_last, 'still-tilting'] = count_transitions(data[1][:],'STILL','TILTING')/n\n",
    "                feature.loc[ind_last, 'still-unknown'] = count_transitions(data[1][:],'STILL','UNKNOWN')/n\n",
    "                feature.loc[ind_last, 'walking-unknown'] = count_transitions(data[1][:],'ONFOOT','UNKNOWN')/n\n",
    "            else:\n",
    "                feature.loc[ind_last, 'still'] = np.nan\n",
    "                feature.loc[ind_last, 'tilting'] = np.nan\n",
    "                feature.loc[ind_last, 'walking'] = np.nan\n",
    "                feature.loc[ind_last, 'unknown act'] = np.nan\n",
    "                feature.loc[ind_last, 'still-walking'] = np.nan\n",
    "                feature.loc[ind_last, 'still-tilting'] = np.nan\n",
    "                feature.loc[ind_last, 'still-unknown'] = np.nan\n",
    "                feature.loc[ind_last, 'walking-unknown'] = np.nan\n",
    "\n",
    "            # apps\n",
    "#             if 'app.csv' in sensors:\n",
    "#                 data = pd.read_csv(sensor_dir+'app.csv', delimiter='\\t', header=None)\n",
    "#                 feature.loc[ind_last, 'messaging'] = np.sum(data[2][:]=='Messaging')\n",
    "#                 feature.loc[ind_last, 'facebook'] = np.sum(data[2][:]=='Facebook')\n",
    "#                 feature.loc[ind_last, 'chrome'] = np.sum(data[2][:]=='Chrome')\n",
    "#                 feature.loc[ind_last, 'mobilyze'] = np.sum(data[2][:]=='Mobilyze')\n",
    "#                 feature.loc[ind_last, 'phone'] = np.sum(data[2][:]=='Phone')\n",
    "#                 feature.loc[ind_last, 'gmail'] = np.sum(data[2][:]=='Gmail')\n",
    "#                 feature.loc[ind_last, 'contacts'] = np.sum(data[2][:]=='Contacts')\n",
    "#                 feature.loc[ind_last, 'internet'] = np.sum(data[2][:]=='Internet')\n",
    "#                 feature.loc[ind_last, 'gallery'] = np.sum(data[2][:]=='Gallery')\n",
    "#                 feature.loc[ind_last, 'email'] = np.sum(data[2][:]=='Email')\n",
    "#                 feature.loc[ind_last, 'settings'] = np.sum(data[2][:]=='Settings')\n",
    "#                 feature.loc[ind_last, 'messenger'] = np.sum(data[2][:]=='Messenger')\n",
    "#                 feature.loc[ind_last, 'camera'] = np.sum(data[2][:]=='Camera')\n",
    "#                 feature.loc[ind_last, 'clock'] = np.sum(data[2][:]=='Clock')\n",
    "#                 feature.loc[ind_last, 'maps'] = np.sum(data[2][:]=='Maps')\n",
    "#                 feature.loc[ind_last, 'calendar'] = np.sum(data[2][:]=='Calendar')\n",
    "#                 feature.loc[ind_last, 'youtube'] = np.sum(data[2][:]=='Youtube')\n",
    "#                 feature.loc[ind_last, 'calculator'] = np.sum(data[2][:]=='Calculator')\n",
    "#                 feature.loc[ind_last, 'purple robot'] = np.sum(data[2][:]=='Purple Robot')\n",
    "#                 feature.loc[ind_last, 'system ui'] = np.sum(data[2][:]=='System UI')\n",
    "#             else:\n",
    "#                 if has_app_data: # if not, leave them as NaN\n",
    "#                     feature.loc[ind_last, 'messaging'] = 0\n",
    "#                     feature.loc[ind_last, 'facebook'] = 0\n",
    "#                     feature.loc[ind_last, 'chrome'] = 0\n",
    "#                     feature.loc[ind_last, 'mobilyze'] = 0\n",
    "#                     feature.loc[ind_last, 'phone'] = 0\n",
    "#                     feature.loc[ind_last, 'gmail'] = 0\n",
    "#                     feature.loc[ind_last, 'contacts'] = 0\n",
    "#                     feature.loc[ind_last, 'internet'] = 0\n",
    "#                     feature.loc[ind_last, 'gallery'] = 0\n",
    "#                     feature.loc[ind_last, 'email'] = 0\n",
    "#                     feature.loc[ind_last, 'settings'] = 0\n",
    "#                     feature.loc[ind_last, 'messenger'] = 0\n",
    "#                     feature.loc[ind_last, 'camera'] = 0\n",
    "#                     feature.loc[ind_last, 'clock'] = 0\n",
    "#                     feature.loc[ind_last, 'maps'] = 0\n",
    "#                     feature.loc[ind_last, 'calendar'] = 0\n",
    "#                     feature.loc[ind_last, 'youtube'] = 0\n",
    "#                     feature.loc[ind_last, 'calculator'] = 0\n",
    "#                     feature.loc[ind_last, 'purple robot'] = 0\n",
    "#                     feature.loc[ind_last, 'system ui'] = 0\n",
    "#                 else:\n",
    "#                     feature.loc[ind_last, 'messaging'] = np.nan\n",
    "#                     feature.loc[ind_last, 'facebook'] = np.nan\n",
    "#                     feature.loc[ind_last, 'chrome'] = np.nan\n",
    "#                     feature.loc[ind_last, 'mobilyze'] = np.nan\n",
    "#                     feature.loc[ind_last, 'phone'] = np.nan\n",
    "#                     feature.loc[ind_last, 'gmail'] = np.nan\n",
    "#                     feature.loc[ind_last, 'contacts'] = np.nan\n",
    "#                     feature.loc[ind_last, 'internet'] = np.nan\n",
    "#                     feature.loc[ind_last, 'gallery'] = np.nan\n",
    "#                     feature.loc[ind_last, 'email'] = np.nan\n",
    "#                     feature.loc[ind_last, 'settings'] = np.nan\n",
    "#                     feature.loc[ind_last, 'messenger'] = np.nan\n",
    "#                     feature.loc[ind_last, 'camera'] = np.nan\n",
    "#                     feature.loc[ind_last, 'clock'] = np.nan\n",
    "#                     feature.loc[ind_last, 'maps'] = np.nan\n",
    "#                     feature.loc[ind_last, 'calendar'] = np.nan\n",
    "#                     feature.loc[ind_last, 'youtube'] = np.nan\n",
    "#                     feature.loc[ind_last, 'calculator'] = np.nan\n",
    "#                     feature.loc[ind_last, 'purple robot'] = np.nan\n",
    "#                     feature.loc[ind_last, 'system ui'] = np.nan\n",
    "\n",
    "            # communication\n",
    "            if 'coe.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'coe.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'call in'] = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='INCOMING'))\n",
    "                feature.loc[ind_last, 'call out'] = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='OUTGOING'))\n",
    "                feature.loc[ind_last, 'sms in'] = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='INCOMING'))\n",
    "                feature.loc[ind_last, 'sms out'] = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='OUTGOING'))\n",
    "                feature.loc[ind_last, 'call missed'] = np.sum(data[4][:]=='MISSED')\n",
    "            else:\n",
    "                feature.loc[ind_last, 'call in'] = 0\n",
    "                feature.loc[ind_last, 'call out'] = 0\n",
    "                feature.loc[ind_last, 'sms in'] = 0\n",
    "                feature.loc[ind_last, 'sms out'] = 0\n",
    "                feature.loc[ind_last, 'call missed'] = 0\n",
    "\n",
    "            # wifi\n",
    "            if 'wif.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'wif.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'n wifi'] = np.mean(data[3][:])\n",
    "            else:\n",
    "                feature.loc[ind_last, 'n wifi'] = np.nan\n",
    "\n",
    "            # weather\n",
    "            if 'wtr.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'wtr.csv', delimiter='\\t', header=None)\n",
    "                wtr_cond = stats.mode(data[9][:])[0][0]\n",
    "                if not isinstance(wtr_cond, basestring):\n",
    "                    wtr_cond = str(wtr_cond)\n",
    "                feature.loc[ind_last, 'temperature'] = np.mean(data[1][:])\n",
    "                feature.loc[ind_last, 'dew point'] = np.mean(data[3][:])\n",
    "                feature.loc[ind_last, 'weather'] = sum(ord(c) for c in wtr_cond)\n",
    "            else:\n",
    "                feature.loc[ind_last, 'temperature'] = np.nan\n",
    "                feature.loc[ind_last, 'dew point'] = np.nan\n",
    "                feature.loc[ind_last, 'weather'] = np.nan\n",
    "\n",
    "            # GPS and time\n",
    "            if 'fus.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'fus.csv', delimiter='\\t', header=None)\n",
    "                t_start = data[0][0]\n",
    "                t_end = data[0][data[0][:].size-1]\n",
    "                feature.loc[ind_last, 'lat mean'] = np.mean(data[1][:])\n",
    "                feature.loc[ind_last, 'lng mean'] = np.mean(data[2][:])\n",
    "                feature.loc[ind_last, 'loc var'] = np.log(np.var(data[1][:])+np.var(data[2][:])+1e-16)\n",
    "                feature.loc[ind_last, 'duration'] = t_end-t_start\n",
    "                feature.loc[ind_last, 'midtime'] = (t_end+t_start)/2.0\n",
    "                feature.loc[ind_last, 'midhour'] = ((t_end+t_start)/2.0)%86400\n",
    "                feature.loc[ind_last, 'dow start'] = datetime.datetime.fromtimestamp(t_start).weekday()\n",
    "                feature.loc[ind_last, 'dow end'] = datetime.datetime.fromtimestamp(t_end).weekday()\n",
    "                feature.loc[ind_last, 'n gps'] = data.shape[0]\n",
    "            else:\n",
    "                feature.loc[ind_last, 'lat mean'] = np.nan\n",
    "                feature.loc[ind_last, 'lng mean'] = np.nan\n",
    "                feature.loc[ind_last, 'loc var'] = np.nan\n",
    "                feature.loc[ind_last, 'duration'] = np.nan\n",
    "                feature.loc[ind_last, 'midtime'] = np.nan\n",
    "                feature.loc[ind_last, 'midhour'] = np.nan\n",
    "                feature.loc[ind_last, 'dow start'] = np.nan\n",
    "                feature.loc[ind_last, 'dow end'] = np.nan\n",
    "                feature.loc[ind_last, 'n gps'] = 0.0\n",
    "\n",
    "            # foursquare location in binary form\n",
    "            loc_fsq_code = le.transform(loc_fsq)\n",
    "            loc_fsq_bin = enc.transform(loc_fsq_code.reshape(-1,1)).toarray()\n",
    "            loc_fsq_bin = loc_fsq_bin[0]\n",
    "            for j in range(loc_fsq_bin.size):\n",
    "                feature.loc[ind_last, 'fsq {}'.format(j)] = loc_fsq_bin[j]\n",
    "\n",
    "            # distance to closest foursquare location (m)\n",
    "            feature.loc[ind_last, 'fsq distance'] = distance_fsq\n",
    "            \n",
    "            # break locations and generate duplicate data for other sensors\n",
    "            if break_locations:\n",
    "                locs = target.loc[ind_last, 'location']\n",
    "                locs = locs[1:-1] # remove brackets\n",
    "                locs = locs.split('\", \"')\n",
    "                locs = [l.replace('\"','') for l in locs]\n",
    "                locs = filter(None, locs) # remove any empty strings\n",
    "                # first repeating everything\n",
    "                for i in range(len(locs)-1):\n",
    "                    target.loc[ind_last+1+i,:] = target.loc[ind_last,:]\n",
    "                    feature.loc[ind_last+1+i,:] = feature.loc[ind_last,:]\n",
    "                # noew replacing locations with new values\n",
    "                for (i,_) in enumerate(locs):\n",
    "                    target.loc[ind_last+i,'location'] = locs[i]\n",
    "                # last index\n",
    "                ind_last += len(locs)\n",
    "                \n",
    "            else:\n",
    "                ind_last += 1\n",
    "\n",
    "        if save_results:\n",
    "            with open('features/'+subj+'.dat', 'w') as file_out:\n",
    "                pickle.dump([feature, target], file_out)\n",
    "            file_out.close()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "subjects = os.listdir('data/')\n",
    "extract_features(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgt mean</th>\n",
       "      <th>lgt std</th>\n",
       "      <th>lgt off</th>\n",
       "      <th>lgt zcrossing</th>\n",
       "      <th>lgt skew</th>\n",
       "      <th>lgt kurt</th>\n",
       "      <th>aud mean</th>\n",
       "      <th>aud std</th>\n",
       "      <th>aud skew</th>\n",
       "      <th>aud kurt</th>\n",
       "      <th>...</th>\n",
       "      <th>dow end</th>\n",
       "      <th>fsq 0</th>\n",
       "      <th>fsq 1</th>\n",
       "      <th>fsq 2</th>\n",
       "      <th>fsq 3</th>\n",
       "      <th>fsq 4</th>\n",
       "      <th>fsq 5</th>\n",
       "      <th>fsq 6</th>\n",
       "      <th>fsq 7</th>\n",
       "      <th>fsq distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.14802</td>\n",
       "      <td>-1.594116</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.14802</td>\n",
       "      <td>-1.594116</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lgt mean  lgt std  lgt off  lgt zcrossing  lgt skew  lgt kurt  aud mean  \\\n",
       "11       NaN      NaN      NaN            NaN       NaN       NaN  0.003797   \n",
       "12       NaN      NaN      NaN            NaN       NaN       NaN  0.003797   \n",
       "\n",
       "     aud std  aud skew  aud kurt      ...       dow end  fsq 0  fsq 1  fsq 2  \\\n",
       "11  0.001438   0.14802 -1.594116      ...           3.0    0.0    0.0    0.0   \n",
       "12  0.001438   0.14802 -1.594116      ...           3.0    0.0    0.0    0.0   \n",
       "\n",
       "    fsq 3  fsq 4  fsq 5  fsq 6  fsq 7  fsq distance  \n",
       "11    0.0    1.0    0.0    0.0    0.0         917.0  \n",
       "12    0.0    1.0    0.0    0.0    0.0         917.0  \n",
       "\n",
       "[2 rows x 70 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "with open('features_breakloc/MQ077WG.dat') as f:\n",
    "    feature, target = pickle.load(f)\n",
    "f.close()\n",
    "pd.options.display.max_rows = 999\n",
    "target.loc[11:12, :]\n",
    "feature.loc[11:12, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spatial visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "colors = plt.cm.jet(np.linspace(0,1,len(loc_uniq)))\n",
    "plt.figure(figsize=(18,15))\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.plot(np.array(lng_gps),np.array(lat_gps),'ko',alpha=0.1, markersize=12)\n",
    "for i in range(len(loc_uniq)):\n",
    "    inds = loc.index(loc_uniq[i])\n",
    "    plt.plot(np.array(lng_report[inds]), np.array(lat_report[inds]), 'o', color=colors[i], alpha=1, markersize=12)\n",
    "plt.legend(['gps']+loc_uniq, frameon=False, loc='center left', bbox_to_anchor=(0.6, 0.8))\n",
    "plt.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporal visualization\n",
    "from sklearn import preprocessing\n",
    "print loc\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(loc)\n",
    "loc_code = le.transform(loc)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(loc_code,'.k',markersize=10)\n",
    "plt.yticks(range(len(loc_uniq)), loc_uniq)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(loc_code)])\n",
    "axes.set_ylim([-1, len(loc_uniq)])\n",
    "print t_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporal visualization\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(state_code,'.k',markersize=10)\n",
    "plt.yticks(range(len(loc_uniq)), loc_uniq)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(state_code)])\n",
    "axes.set_ylim([-1, len(loc_uniq)])\n",
    "print loc_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distribution of features across locations\n",
    "ft = 0\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(state_code+np.random.uniform(-.1,.1,len(state_code)), feature[:,ft],'.',markersize=20, alpha=.5)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-.5, len(loc_uniq)-.5])\n",
    "plt.xticks(range(len(loc_uniq)), loc_uniq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
